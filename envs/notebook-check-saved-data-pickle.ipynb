{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/Z-LabData-6T/zlf-nfs-hdd/projects/2020-OORL/ObjectOrientedRL\n"
     ]
    }
   ],
   "source": [
    "%cd '/mnt/Z-LabData-6T/zlf-nfs-hdd/projects/2020-OORL/ObjectOrientedRL'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from envs.object_library_block_pushing import get_cascade_library"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from envs.object_library_block_pushing import load_env_library, save_env_library"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# outline\n",
    "\n",
    "- load pickle and try to init model\n",
    "- load actual data\n",
    "- load model\n",
    "- inference and visualize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load pickled library"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "env_dict, pool_dict = load_env_library('Data/shapes_library_100train3eval_apr08_maxN50_2022-04-08-00-28-43_cascade.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<envs.block_pushing.BlockPushingWithLibrary at 0x7f649c18b310>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_dict[10]['train']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load actual data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from utils.utils_cswm import StateTransitionsDatasetObjConfig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# path = '/mnt/Z-LabData-6T/zlf-nfs-hdd/projects/2020-OORL/datasets'\n",
    "path = '/home/zlf/datasets_ssd/oorl'\n",
    "file = 'shapes_library_100train1eval_jan24_cascade_n10k5_train.h5'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> finish loading into memory\n",
      "> Visualization keys: dict_keys(['column', 'ordered'])\n"
     ]
    }
   ],
   "source": [
    "dataset = StateTransitionsDatasetObjConfig(hdf5_file='/'.join([path, file]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "obs, action, next_obs, neg_obs = dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 50, 50)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# from utils.utils_load_model import get_model_checkpoint\n",
    "from utils.utils_loading import get_model_checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# > a representation checkpoint\n",
    "model_folder = './checkpoints/decoupled-homo-slot-attention-experiments/2022-01-25-00-02-35/final-2022-01-25T16:23:53.709283'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Merged config] action_dim: 4\n",
      "action_encoding: false\n",
      "action_hidden_dims:\n",
      "- 32\n",
      "action_size: 4\n",
      "batch_size: 1024\n",
      "copy_action: false\n",
      "dataset: /mnt_host/zlf-local-data/oorl/shapes_library_100train1eval_jan24_cascade_n50k5_train.h5\n",
      "decoder: false\n",
      "decoupled_homo_att: true\n",
      "embedding_dim: 4\n",
      "enable_amp: false\n",
      "encoder: small\n",
      "encoder_batch_norm: true\n",
      "encoder_type: specific-small2\n",
      "eval_interval: 20\n",
      "exp_folder: checkpoints/decoupled-homo-slot-attention-experiments/2022-01-25-00-02-35/final-2022-01-25T16:23:53.709283/\n",
      "first_kernel_size: 5\n",
      "folder_pl: checkpoints_pl\n",
      "gpus: 1\n",
      "hidden_dim: 512\n",
      "hidden_dims_encoder:\n",
      "- 32\n",
      "- 32\n",
      "- 16\n",
      "hinge: 1.0\n",
      "homo_att_ver: mapping_full_detach\n",
      "homo_slot_att: false\n",
      "identity_encoding: false\n",
      "ignore_action: false\n",
      "input_dims:\n",
      "- 3\n",
      "- 50\n",
      "- 50\n",
      "input_resolution:\n",
      "- 50\n",
      "- 50\n",
      "kernel_size: 5\n",
      "log_interval: 20\n",
      "mask_att_cswm: false\n",
      "no_last_slot: false\n",
      "num_iterations: 3\n",
      "num_objects: 5\n",
      "num_objects_total: 50\n",
      "num_workers: 16\n",
      "obj_encoder_type: mlp\n",
      "representation:\n",
      "  batch_size: 256\n",
      "  decay_epochs_pct: 0.4\n",
      "  decay_gamma: 0.5\n",
      "  enable_scheduler: true\n",
      "  epochs: 300\n",
      "  lr: 0.001\n",
      "  n_samples: 3\n",
      "  num_sanity_val_steps: 1\n",
      "  warmup_epochs_pct: 0.1\n",
      "  weight_decay: 0.0\n",
      "representation_checkpoint: None\n",
      "same_config_ratio: 0.5\n",
      "save_folder: checkpoints\n",
      "save_interval: 10\n",
      "sigma: 0.5\n",
      "slot_size: 16\n",
      "transition:\n",
      "  batch_size: 5120\n",
      "  decay_epochs_pct: 0.4\n",
      "  decay_gamma: 0.5\n",
      "  enable_scheduler: true\n",
      "  epochs: 0\n",
      "  lr: 0.003\n",
      "  warmup_epochs_pct: 0.05\n",
      "transition_type: gnn\n",
      "vanilla_cswm: false\n",
      "vis_interval: 2\n",
      "\n",
      ">>> kwargs - extra dict_keys(['action_size', 'batch_size', 'dataset', 'decoder', 'decoupled_homo_att', 'enable_amp', 'encoder', 'eval_interval', 'exp_folder', 'folder_pl', 'gpus', 'homo_att_ver', 'homo_slot_att', 'input_dims', 'log_interval', 'mask_att_cswm', 'num_workers', 'obj_encoder_type', 'representation', 'representation_checkpoint', 'same_config_ratio', 'save_folder', 'save_interval', 'transition', 'vanilla_cswm', 'vis_interval'])\n",
      "[transition net] <class 'algorithms.world_model.TransitionGNN'> TransitionGNN(\n",
      "  (edge_mlp): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (node_mlp): Sequential(\n",
      "    (0): Linear(in_features=520, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zlf/anaconda3/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Inited model] DecoupledHomomorphicWM(\n",
      "  (slot_attention): DecoupledSlotAttentionModel(\n",
      "    (slot_attention): SlotAttention(\n",
      "      (norm_inputs): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_slots): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_mlp): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (project_q): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (project_k): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (project_v): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (gru): GRUCell(16, 16)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=16, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder): EncoderSmall2(\n",
      "      (net): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(5, 5))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.01)\n",
      "        (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): LeakyReLU(negative_slope=0.01)\n",
      "        (9): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (encoder_pos_embedding): SoftPositionEmbed(\n",
      "        (dense): Linear(in_features=4, out_features=16, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_out_layer): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (decoder): DecoderSmall2(\n",
      "      (out): Sequential(\n",
      "        (0): ConvTranspose2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): ConvTranspose2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.01)\n",
      "        (4): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.01)\n",
      "        (6): ConvTranspose2d(32, 4, kernel_size=(5, 5), stride=(5, 5))\n",
      "      )\n",
      "      (decoder_pos_embedding): SoftPositionEmbed(\n",
      "        (dense): Linear(in_features=4, out_features=16, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pixel_slots_out): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (action_slots_out): Identity()\n",
      "  (transition_model): TransitionGNN(\n",
      "    (edge_mlp): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (node_mlp): Sequential(\n",
      "      (0): Linear(in_features=520, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=512, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (action_attention): ActionBindingAttention(\n",
      "    (action_encoder): Identity()\n",
      "    (identity_encoder): Identity()\n",
      "    (norm_actions): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (project_q_action): Linear(in_features=16, out_features=50, bias=False)\n",
      "    (project_k_action): Linear(in_features=50, out_features=50, bias=False)\n",
      "    (project_v_action): Linear(in_features=4, out_features=4, bias=False)\n",
      "  )\n",
      ")\n",
      "[Loaded model] DecoupledHomomorphicWM(\n",
      "  (slot_attention): DecoupledSlotAttentionModel(\n",
      "    (slot_attention): SlotAttention(\n",
      "      (norm_inputs): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_slots): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_mlp): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (project_q): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (project_k): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (project_v): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (gru): GRUCell(16, 16)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=16, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder): EncoderSmall2(\n",
      "      (net): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(5, 5))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.01)\n",
      "        (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): LeakyReLU(negative_slope=0.01)\n",
      "        (9): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (encoder_pos_embedding): SoftPositionEmbed(\n",
      "        (dense): Linear(in_features=4, out_features=16, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (encoder_out_layer): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (decoder): DecoderSmall2(\n",
      "      (out): Sequential(\n",
      "        (0): ConvTranspose2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): ConvTranspose2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): LeakyReLU(negative_slope=0.01)\n",
      "        (4): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): LeakyReLU(negative_slope=0.01)\n",
      "        (6): ConvTranspose2d(32, 4, kernel_size=(5, 5), stride=(5, 5))\n",
      "      )\n",
      "      (decoder_pos_embedding): SoftPositionEmbed(\n",
      "        (dense): Linear(in_features=4, out_features=16, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pixel_slots_out): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (action_slots_out): Identity()\n",
      "  (transition_model): TransitionGNN(\n",
      "    (edge_mlp): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (node_mlp): Sequential(\n",
      "      (0): Linear(in_features=520, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=512, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (action_attention): ActionBindingAttention(\n",
      "    (action_encoder): Identity()\n",
      "    (identity_encoder): Identity()\n",
      "    (norm_actions): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (project_q_action): Linear(in_features=16, out_features=50, bias=False)\n",
      "    (project_k_action): Linear(in_features=50, out_features=50, bias=False)\n",
      "    (project_v_action): Linear(in_features=4, out_features=4, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = get_model_checkpoint(save_folder=model_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# inference the model and evaluate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# from scripts.training_decoupled import plot_binding\n",
    "from utils.utils_visualize import plot_binding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO need to get from there, need to feed data\n",
    "model.get_binding_instance()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_binding(info={\n",
    "\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}